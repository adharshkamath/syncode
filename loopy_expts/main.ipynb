{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from typing import Tuple\n",
    "from syncode import Syncode\n",
    "from utils import Logger\n",
    "\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__), '../'))\n",
    "\n",
    "def init(model: str, grammar: str):\n",
    "    syncode = Syncode(model = model, mode='grammar_mask', grammar=grammar, parse_output_only=True, log_level=2, max_new_tokens=10000, device='cuda:0')\n",
    "    return syncode\n",
    "\n",
    "def main(\n",
    "        llm: Syncode,\n",
    "        datasets_file: str,\n",
    "        prompt: Tuple[str, str],\n",
    "        num_samples: int = 1,\n",
    "):\n",
    "    Logger.debug = True\n",
    "    try:\n",
    "        Logger.log_info(f\"Reading benchmarks file from {datasets_file}\")\n",
    "        benchmarks_file = open(datasets_file, 'r')\n",
    "        benchmarks = benchmarks_file.read().split('\\n')\n",
    "        benchmarks_file.close()\n",
    "        Logger.log_info(f\"Read {len(benchmarks)} benchmarks\")\n",
    "        prompt_system_file, prompt_text_file = open(prompt[0], 'r'), open(prompt[1], 'r')\n",
    "        prompt_system = prompt_system_file.read()\n",
    "        prompt_text = prompt_text_file.read()\n",
    "        prompt_system_file.close(), prompt_text_file.close()\n",
    "\n",
    "        expt_logs = []\n",
    "\n",
    "        for i, benchmark in enumerate(benchmarks):\n",
    "            try:\n",
    "                Logger.log_info(f\"[{i + 1}/{len(benchmarks)}] Processing benchmark {benchmark}\")\n",
    "                benchmark_code = open(benchmark, 'r').read()\n",
    "                prompt_text_template = deepcopy(prompt_text)\n",
    "                prompt = prompt_system + '\\n' + prompt_text_template.format(code = benchmark_code)\n",
    "                benchmark_log = {\n",
    "                    'file': benchmark,\n",
    "                    'prompt': prompt,\n",
    "                    'completions': []\n",
    "                }\n",
    "                Logger.log_model_request(llm.model_name, [{'role': 'Prompt', 'content': prompt}])\n",
    "                for i in range(num_samples):\n",
    "                    Logger.log_info(f\"Generating sample {i + 1}/{num_samples}\")\n",
    "                    result = llm.infer(prompt)\n",
    "                    Logger.log_model_response(llm.model_name, [result])\n",
    "                    benchmark_log['completions'].append(result)\n",
    "                \n",
    "                expt_logs.append(benchmark_log)\n",
    "            except Exception as e:\n",
    "                Logger.log_error(f'Error in benchmark {benchmark} sample {i}: {e}')\n",
    "                benchmark_log['error'] = str(e)\n",
    "                expt_logs.append(benchmark_log)\n",
    "    except KeyboardInterrupt:\n",
    "        Logger.log_info('Received keyboard interrupt. Exiting...')\n",
    "    \n",
    "    return expt_logs\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = '/data/share/models/hugging_face/models--Qwen--Qwen2.5-Coder-1.5B/snapshots/835b517c690ba0a4a54212e87a0d6ab1a7fc03d0/'\n",
    "    grammar = 'invariants.lark'\n",
    "    Logger.log_info(f\"Initializing model {model}\")\n",
    "    Logger.log_info(f\"Initializing grammar {grammar}\")\n",
    "    llm = init(model, grammar)\n",
    "    datasets_file = 'benchmarks.txt'\n",
    "    prompt = ('templates/system_text.txt', 'templates/prompt_text.txt')\n",
    "    num_samples = 10\n",
    "\n",
    "    expt_logs = main(llm, datasets_file, prompt, num_samples)\n",
    "    log_file_name = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\") + '_expt_logs.json'\n",
    "    with open(log_file_name, 'w') as log_file:\n",
    "        json.dump(expt_logs, log_file, indent=4)\n",
    "\n",
    "    print(f'Logs saved to {log_file_name}')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
